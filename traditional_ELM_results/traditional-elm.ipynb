{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#traditional ELM on MNIST\nimport numpy as np\nfrom tensorflow.keras.datasets import mnist\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import accuracy_score\n\nclass ELM:\n    def __init__(self, input_dim, hidden_dim, activation='sigmoid'):\n        self.input_dim = input_dim\n        self.hidden_dim = hidden_dim\n        self.activation = activation\n        self.W = np.random.randn(self.hidden_dim, self.input_dim)\n        self.b = np.random.randn(self.hidden_dim)\n\n    def _activation(self, x):\n        if self.activation == 'sigmoid':\n            return 1 / (1 + np.exp(-x))\n        elif self.activation == 'tanh':\n            return np.tanh(x)\n        else:\n            raise ValueError(\"Unsupported activation function.\")\n\n    def fit(self, X, y):\n        H = self._activation(np.dot(X, self.W.T) + self.b)\n        self.beta = np.dot(np.linalg.pinv(H), y)\n\n    def predict(self, X):\n        H = self._activation(np.dot(X, self.W.T) + self.b)\n        y_pred = np.dot(H, self.beta)\n        return y_pred\n\n# Load MNIST from keras (with predefined train/test split)\nprint(\"Loading MNIST dataset...\")\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n\n# Preprocessing\nX_train = X_train.reshape(-1, 28*28).astype(np.float32) / 255.0\nX_test = X_test.reshape(-1, 28*28).astype(np.float32) / 255.0\n\n# One-hot encode labels\nencoder = LabelBinarizer()\nY_train = encoder.fit_transform(y_train)\nY_test = encoder.transform(y_test)\n\n# Initialize and train ELM\nprint(\"Training ELM...\")\nelm = ELM(input_dim=784, hidden_dim=1000, activation='sigmoid')\nelm.fit(X_train, Y_train)\n\n# Predict and evaluate\nprint(\"Evaluating...\")\ny_pred_probs = elm.predict(X_test)\ny_pred = np.argmax(y_pred_probs, axis=1)\n\nacc = accuracy_score(y_test, y_pred)\nprint(f\"Test Accuracy: {acc * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T21:57:21.666693Z","iopub.execute_input":"2025-06-26T21:57:21.666906Z","iopub.status.idle":"2025-06-26T21:57:57.743287Z","shell.execute_reply.started":"2025-06-26T21:57:21.666886Z","shell.execute_reply":"2025-06-26T21:57:57.742441Z"}},"outputs":[{"name":"stderr","text":"2025-06-26 21:57:23.673814: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750975043.936886      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750975044.006525      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Loading MNIST dataset...\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nTraining ELM...\nEvaluating...\nTest Accuracy: 93.27%\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"#traditional ELM on fashion-MNIST\nimport numpy as np\nfrom tensorflow.keras.datasets import fashion_mnist\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import accuracy_score\n\nclass ELM:\n    def __init__(self, input_dim, hidden_dim, activation='sigmoid'):\n        self.input_dim = input_dim\n        self.hidden_dim = hidden_dim\n        self.activation = activation\n        self.W = np.random.randn(self.hidden_dim, self.input_dim)\n        self.b = np.random.randn(self.hidden_dim)\n\n    def _activation(self, x):\n        if self.activation == 'sigmoid':\n            return 1 / (1 + np.exp(-x))\n        elif self.activation == 'tanh':\n            return np.tanh(x)\n        else:\n            raise ValueError(\"Unsupported activation\")\n\n    def fit(self, X, y):\n        H = self._activation(np.dot(X, self.W.T) + self.b)\n        self.beta = np.dot(np.linalg.pinv(H), y)\n\n    def predict(self, X):\n        H = self._activation(np.dot(X, self.W.T) + self.b)\n        return np.dot(H, self.beta)\n\n# Load Fashion-MNIST\nprint(\"Loading Fashion-MNIST...\")\n(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\nX_train = X_train.reshape(-1, 28*28).astype(np.float32) / 255.0\nX_test = X_test.reshape(-1, 28*28).astype(np.float32) / 255.0\n\n# One-hot encode\nencoder = LabelBinarizer()\nY_train = encoder.fit_transform(y_train)\nY_test = encoder.transform(y_test)\n\n# Train ELM\nelm = ELM(input_dim=784, hidden_dim=1000, activation='sigmoid')\nelm.fit(X_train, Y_train)\n\n# Evaluate\ny_pred_probs = elm.predict(X_test)\ny_pred = np.argmax(y_pred_probs, axis=1)\nacc = accuracy_score(y_test, y_pred)\nprint(f\"Fashion-MNIST Accuracy: {acc * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T21:59:18.064670Z","iopub.execute_input":"2025-06-26T21:59:18.065598Z","iopub.status.idle":"2025-06-26T21:59:33.645715Z","shell.execute_reply.started":"2025-06-26T21:59:18.065541Z","shell.execute_reply":"2025-06-26T21:59:33.644785Z"}},"outputs":[{"name":"stdout","text":"Loading Fashion-MNIST...\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nFashion-MNIST Accuracy: 84.42%\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"#traditional ELM on K-MNIST\n\nimport numpy as np\nimport tensorflow_datasets as tfds\n\ndef load_kmnist_tfds():\n    ds_train, ds_test = tfds.load('kmnist', split=['train', 'test'], as_supervised=True, batch_size=-1)\n    x_tr, y_tr = tfds.as_numpy(ds_train)\n    x_te, y_te = tfds.as_numpy(ds_test)\n\n    # Reshape and normalize\n    x_tr = x_tr.reshape(-1, 28 * 28).astype(np.float32).T / 255.0  # shape: (784, N)\n    x_te = x_te.reshape(-1, 28 * 28).astype(np.float32).T / 255.0\n    return x_tr, y_tr, x_te, y_te\n\nclass ELM_CPU:\n    def __init__(self, input_dim, hidden_dim, activation='sigmoid'):\n        self.input_dim = input_dim\n        self.hidden_dim = hidden_dim\n        self.activation = activation\n        self.W = np.random.randn(hidden_dim, input_dim)\n        self.b = np.random.randn(hidden_dim, 1)\n\n    def _activation(self, x):\n        if self.activation == 'sigmoid':\n            return 1 / (1 + np.exp(-x))\n        elif self.activation == 'tanh':\n            return np.tanh(x)\n        else:\n            raise ValueError(\"Unsupported activation function.\")\n\n    def fit(self, X, Y):\n        H = self._activation(self.W @ X + self.b)  # H shape: (hidden_dim, N)\n        self.beta = np.linalg.pinv(H.T) @ Y.T      # beta shape: (hidden_dim, 10)\n\n    def predict(self, X):\n        H = self._activation(self.W @ X + self.b)\n        Y_pred = self.beta.T @ H                   # shape: (10, N)\n        return np.argmax(Y_pred, axis=0)\n\n# Load and preprocess KMNIST data\nx_tr, y_tr, x_te, y_te = load_kmnist_tfds()\nY_train = (np.eye(10)[y_tr].T * 2) - 1            # shape: (10, N), values in {-1, 1}\n\n# Initialize and train ELM\nelm = ELM_CPU(input_dim=784, hidden_dim=1000, activation='sigmoid')\nelm.fit(x_tr, Y_train)\n\n# Predict\ny_pred = elm.predict(x_te)\n\n# Evaluate\naccuracy = np.mean(y_pred == y_te)\nprint(f\"KMNIST Accuracy (CPU only): {accuracy * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T22:07:51.366296Z","iopub.execute_input":"2025-06-26T22:07:51.366639Z","iopub.status.idle":"2025-06-26T22:08:09.363154Z","shell.execute_reply.started":"2025-06-26T22:07:51.366616Z","shell.execute_reply":"2025-06-26T22:08:09.362312Z"}},"outputs":[{"name":"stdout","text":"KMNIST Accuracy (CPU only): 70.07%\n","output_type":"stream"}],"execution_count":5}]}